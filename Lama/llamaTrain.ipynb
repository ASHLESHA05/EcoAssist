{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\py_venv\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: datasets in d:\\py_venv\\lib\\site-packages (3.3.2)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.15.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.3-py3-none-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: filelock in d:\\py_venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in d:\\py_venv\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\py_venv\\lib\\site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\py_venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\py_venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\py_venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\py_venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\py_venv\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\py_venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\py_venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\py_venv\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\py_venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\py_venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in d:\\py_venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\py_venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in d:\\py_venv\\lib\\site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: psutil in d:\\py_venv\\lib\\site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in d:\\py_venv\\lib\\site-packages (from accelerate) (2.6.0+cu126)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\py_venv\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\py_venv\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\py_venv\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\py_venv\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\py_venv\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\py_venv\\lib\\site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\py_venv\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\py_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\py_venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\py_venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\py_venv\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\py_venv\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: networkx in d:\\py_venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\py_venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\py_venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (76.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\py_venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\py_venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\py_venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\py_venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\py_venv\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\py_venv\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\py_venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\py_venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Downloading accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "Downloading peft-0.15.0-py3-none-any.whl (410 kB)\n",
      "Downloading bitsandbytes-0.45.3-py3-none-win_amd64.whl (75.4 MB)\n",
      "   ---------------------------------------- 0.0/75.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/75.4 MB 5.6 MB/s eta 0:00:14\n",
      "    --------------------------------------- 1.8/75.4 MB 4.6 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 3.1/75.4 MB 5.4 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 5.0/75.4 MB 6.3 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 6.8/75.4 MB 7.0 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 8.7/75.4 MB 7.6 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 11.3/75.4 MB 7.9 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 14.2/75.4 MB 8.7 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 17.3/75.4 MB 9.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 21.5/75.4 MB 10.6 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 24.4/75.4 MB 10.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 28.8/75.4 MB 11.8 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 33.6/75.4 MB 12.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 38.5/75.4 MB 13.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 42.2/75.4 MB 13.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 45.9/75.4 MB 14.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 49.5/75.4 MB 14.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 53.2/75.4 MB 14.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 54.3/75.4 MB 14.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 55.3/75.4 MB 13.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 57.1/75.4 MB 13.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 62.1/75.4 MB 13.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 66.1/75.4 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 68.2/75.4 MB 13.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 72.1/75.4 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  75.2/75.4 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 75.4/75.4 MB 13.7 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 992.0/992.0 kB 7.8 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Installing collected packages: sentencepiece, fsspec, bitsandbytes, accelerate, peft\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "Successfully installed accelerate-1.5.2 bitsandbytes-0.45.3 fsspec-2024.12.0 peft-0.15.0 sentencepiece-0.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ultralytics 8.3.75 requires numpy<=2.1.1,>=1.23.0, but you have numpy 2.2.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.19.8-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in d:\\py_venv\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.8.0 (from gradio)\n",
      "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in d:\\py_venv\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in d:\\py_venv\\lib\\site-packages (from gradio) (0.29.3)\n",
      "Requirement already satisfied: jinja2<4.0 in d:\\py_venv\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in d:\\py_venv\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in d:\\py_venv\\lib\\site-packages (from gradio) (2.2.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: packaging in d:\\py_venv\\lib\\site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in d:\\py_venv\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in d:\\py_venv\\lib\\site-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in d:\\py_venv\\lib\\site-packages (from gradio) (2.10.6)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in d:\\py_venv\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.11.2-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in d:\\py_venv\\lib\\site-packages (from gradio) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in d:\\py_venv\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in d:\\py_venv\\lib\\site-packages (from gradio-client==1.8.0->gradio) (2024.12.0)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.8.0->gradio)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in d:\\py_venv\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in d:\\py_venv\\lib\\site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in d:\\py_venv\\lib\\site-packages (from wandb) (5.29.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in d:\\py_venv\\lib\\site-packages (from wandb) (6.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in d:\\py_venv\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.24.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.5-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in d:\\py_venv\\lib\\site-packages (from wandb) (76.1.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\py_venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\py_venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: colorama in d:\\py_venv\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in d:\\py_venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: certifi in d:\\py_venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\py_venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\py_venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in d:\\py_venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\py_venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\py_venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\py_venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\py_venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\py_venv\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\py_venv\\lib\\site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\py_venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\py_venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\py_venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\py_venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\py_venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\py_venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\py_venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-5.22.0-py3-none-any.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/46.2 MB 5.6 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.6/46.2 MB 4.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 2.9/46.2 MB 5.4 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.7/46.2 MB 4.7 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 6.0/46.2 MB 6.1 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 8.9/46.2 MB 7.6 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 11.8/46.2 MB 8.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 15.2/46.2 MB 9.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 17.0/46.2 MB 9.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 19.9/46.2 MB 10.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.3/46.2 MB 10.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 27.0/46.2 MB 11.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 30.9/46.2 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 34.3/46.2 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.5/46.2 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.8/46.2 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.8/46.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.4/46.2 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 12.0 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
      "Downloading wandb-0.19.8-py3-none-win_amd64.whl (20.2 MB)\n",
      "   ---------------------------------------- 0.0/20.2 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 3.9/20.2 MB 21.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 8.4/20.2 MB 20.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 11.0/20.2 MB 18.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 16.0/20.2 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 19.1/20.2 MB 18.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 20.2/20.2 MB 18.2 MB/s eta 0:00:00\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.2-py3-none-win_amd64.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.9/11.4 MB 23.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.6/11.4 MB 18.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.4 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 17.3 MB/s eta 0:00:00\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading sentry_sdk-2.24.0-py2.py3-none-any.whl (336 kB)\n",
      "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading setproctitle-1.3.5-cp312-cp312-win_amd64.whl (12 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pydub, websockets, tomlkit, smmap, setproctitle, sentry-sdk, semantic-version, ruff, python-multipart, orjson, groovy, ffmpy, docker-pycreds, aiofiles, uvicorn, starlette, gitdb, safehttpx, gradio-client, gitpython, fastapi, wandb, gradio\n",
      "Successfully installed aiofiles-23.2.1 docker-pycreds-0.4.0 fastapi-0.115.11 ffmpy-0.5.0 gitdb-4.0.12 gitpython-3.1.44 gradio-5.22.0 gradio-client-1.8.0 groovy-0.1.2 orjson-3.10.15 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 sentry-sdk-2.24.0 setproctitle-1.3.5 smmap-5.0.2 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0 wandb-0.19.8 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers datasets accelerate peft bitsandbytes sentencepiece\n",
    "! pip install gradio wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Encoding: utf-8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eaf702533204b29822a2664c3744639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb627df7bfb4ca3a9bcf353e7c13266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1800 training examples and 200 validation examples\n",
      "Sample instruction: Give me 4 suggestion tips on reduction of Carbon footprint based on my user data.\n",
      "Sample input: \n",
      "                USER BEHAVIOR DATA:\n",
      "                - Eco-Score: 36.8\n",
      "                - Carbon Footprint [kg] total: 12648.06\n",
      "                - Transport: 3724.35\n",
      "                - Home: 3375.01\n",
      "    ...\n",
      "Sample output: Based on your data, I notice your highest carbon footprint comes from Transport. Here are 4 personalized recommendations to reduce your carbon footprint:\n",
      "\n",
      "1. **Avoid flying if possible**: Traveling by...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load your JSON data\n",
    "import chardet\n",
    "\n",
    "with open(r'D:\\Projects\\Carbon_tracker\\Datasets\\LLM\\sugessiosn.json', 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    encoding = result['encoding']\n",
    "\n",
    "print(f\"Detected Encoding: {encoding}\")\n",
    "\n",
    "# Read the file using the detected encoding\n",
    "with open(r'D:\\Projects\\Carbon_tracker\\Datasets\\LLM\\sugessiosn.json', 'r', encoding=encoding) as f:\n",
    "    reference_data = json.load(f)\n",
    "\n",
    "\n",
    "# Function to generate synthetic user profiles\n",
    "def generate_user_profiles(num_profiles=1000):\n",
    "    profiles = []\n",
    "    \n",
    "    for i in range(num_profiles):\n",
    "        # Generate random user behavior data\n",
    "        transport_footprint = random.uniform(500, 5000)\n",
    "        home_footprint = random.uniform(1000, 8000)\n",
    "        food_footprint = random.uniform(800, 4000)\n",
    "        shopping_footprint = random.uniform(300, 3000)\n",
    "        \n",
    "        total_footprint = transport_footprint + home_footprint + food_footprint + shopping_footprint\n",
    "        \n",
    "        # Transport details\n",
    "        transport_modes = [\"car\", \"public transport\", \"bicycle\", \"walking\", \"carpooling\", \"electric vehicle\"]\n",
    "        transport_mode = random.choice(transport_modes)\n",
    "        distance = random.uniform(5, 50) if transport_mode in [\"car\", \"public transport\"] else random.uniform(1, 10)\n",
    "        \n",
    "        # Home details\n",
    "        energy_sources = [\"grid electricity\", \"solar panels\", \"wind power\", \"mixed renewable\"]\n",
    "        heating_types = [\"gas\", \"electric\", \"oil\", \"heat pump\", \"wood\"]\n",
    "        energy_source = random.choice(energy_sources)\n",
    "        heating_type = random.choice(heating_types)\n",
    "        electricity_usage = random.uniform(100, 800)\n",
    "        \n",
    "        # Food details\n",
    "        diet_types = [\"omnivore\", \"vegetarian\", \"vegan\", \"pescatarian\", \"flexitarian\"]\n",
    "        food_waste_levels = [\"high\", \"medium\", \"low\", \"minimal\"]\n",
    "        organic_levels = [\"none\", \"occasional\", \"frequent\", \"exclusively\"]\n",
    "        \n",
    "        diet_type = random.choice(diet_types)\n",
    "        food_waste = random.choice(food_waste_levels)\n",
    "        organic_consumption = random.choice(organic_levels)\n",
    "        \n",
    "        # Savings and plans\n",
    "        water_saved = random.uniform(0, 1000)\n",
    "        energy_saved = random.uniform(0, 2000)\n",
    "        waste_reduced = random.uniform(0, 500)\n",
    "        \n",
    "        # Choose a random plan from the categories in the reference data\n",
    "        all_categories = reference_data[\"categories\"]\n",
    "        random_category = random.choice(all_categories)\n",
    "        random_tip = random.choice(random_category[\"tips\"])\n",
    "        \n",
    "        plan = {\n",
    "            \"title\": random_tip[\"title\"],\n",
    "            \"description\": random_tip[\"description\"]\n",
    "        }\n",
    "        \n",
    "        # Determine the highest footprint area\n",
    "        footprints = {\n",
    "            \"Transport\": transport_footprint,\n",
    "            \"Home\": home_footprint,\n",
    "            \"Food\": food_footprint,\n",
    "            \"Shopping\": shopping_footprint\n",
    "        }\n",
    "        highest_area = max(footprints, key=footprints.get)\n",
    "        \n",
    "        # Calculate eco-score (0-100)\n",
    "        max_possible_footprint = 20000  # Theoretical maximum\n",
    "        eco_score = max(0, min(100, 100 - (total_footprint / max_possible_footprint * 100)))\n",
    "        \n",
    "        profile = {\n",
    "            \"user_id\": i,\n",
    "            \"eco_score\": round(eco_score, 1),\n",
    "            \"carbon_footprint_total\": round(total_footprint, 2),\n",
    "            \"carbon_footprint_breakdown\": {\n",
    "                \"transport\": round(transport_footprint, 2),\n",
    "                \"home\": round(home_footprint, 2),\n",
    "                \"food\": round(food_footprint, 2),\n",
    "                \"shopping\": round(shopping_footprint, 2)\n",
    "            },\n",
    "            \"savings\": {\n",
    "                \"water_saved\": round(water_saved, 2),\n",
    "                \"energy_saved\": round(energy_saved, 2),\n",
    "                \"waste_reduced\": round(waste_reduced, 2)\n",
    "            },\n",
    "            \"user_plan\": plan,\n",
    "            \"current_activities\": {\n",
    "                \"transport\": {\n",
    "                    \"mode\": transport_mode,\n",
    "                    \"distance_km_per_day\": round(distance, 1)\n",
    "                },\n",
    "                \"home\": {\n",
    "                    \"energy_source\": energy_source,\n",
    "                    \"electricity_usage_kwh_per_month\": round(electricity_usage, 2),\n",
    "                    \"heating_type\": heating_type\n",
    "                },\n",
    "                \"food\": {\n",
    "                    \"diet_type\": diet_type,\n",
    "                    \"food_waste\": food_waste,\n",
    "                    \"organic_consumption\": organic_consumption\n",
    "                }\n",
    "            },\n",
    "            \"highest_footprint_area\": highest_area\n",
    "        }\n",
    "        \n",
    "        profiles.append(profile)\n",
    "    \n",
    "    return profiles\n",
    "\n",
    "# Function to create recommendation examples\n",
    "def create_recommendation_examples(user_profiles, reference_data):\n",
    "    examples = []\n",
    "    \n",
    "    for profile in user_profiles:\n",
    "        # Determine which area to focus on\n",
    "        highest_area = profile[\"highest_footprint_area\"]\n",
    "        \n",
    "        # Find the corresponding category in the reference data\n",
    "        relevant_tips = []\n",
    "        for category in reference_data[\"categories\"]:\n",
    "            if category[\"name\"] == highest_area:\n",
    "                relevant_tips = category[\"tips\"]\n",
    "                break\n",
    "        \n",
    "        # If no direct match, use all tips\n",
    "        if not relevant_tips:\n",
    "            relevant_tips = [tip for category in reference_data[\"categories\"] for tip in category[\"tips\"]]\n",
    "        \n",
    "        # Select 4 relevant tips\n",
    "        selected_tips = random.sample(relevant_tips, min(4, len(relevant_tips)))\n",
    "        \n",
    "        # Format the instruction\n",
    "        instruction = \"Give me 4 suggestion tips on reduction of Carbon footprint based on my user data.\"\n",
    "        \n",
    "        # Format the input context\n",
    "        input_context = f\"\"\"\n",
    "                USER BEHAVIOR DATA:\n",
    "                - Eco-Score: {profile[\"eco_score\"]}\n",
    "                - Carbon Footprint [kg] total: {profile[\"carbon_footprint_total\"]}\n",
    "                - Transport: {profile[\"carbon_footprint_breakdown\"][\"transport\"]}\n",
    "                - Home: {profile[\"carbon_footprint_breakdown\"][\"home\"]}\n",
    "                - Food: {profile[\"carbon_footprint_breakdown\"][\"food\"]}\n",
    "                - Shopping: {profile[\"carbon_footprint_breakdown\"][\"shopping\"]}\n",
    "                - Water Saved: {profile[\"savings\"][\"water_saved\"]}\n",
    "                - Energy Saved: {profile[\"savings\"][\"energy_saved\"]}\n",
    "                - Waste Reduced: {profile[\"savings\"][\"waste_reduced\"]}\n",
    "                - User Plan: {profile[\"user_plan\"][\"title\"]} - {profile[\"user_plan\"][\"description\"]}\n",
    "                - Current User Activity:\n",
    "                - Mode of transport: {profile[\"current_activities\"][\"transport\"][\"mode\"]}, distance: {profile[\"current_activities\"][\"transport\"][\"distance_km_per_day\"]} km/day\n",
    "                - Home Energy source: {profile[\"current_activities\"][\"home\"][\"energy_source\"]}, Electricity Usage: {profile[\"current_activities\"][\"home\"][\"electricity_usage_kwh_per_month\"]} kWh/month, Heating Type: {profile[\"current_activities\"][\"home\"][\"heating_type\"]}\n",
    "                - Food diet type: {profile[\"current_activities\"][\"food\"][\"diet_type\"]}, Food Waste: {profile[\"current_activities\"][\"food\"][\"food_waste\"]}, Organic food consumption: {profile[\"current_activities\"][\"food\"][\"organic_consumption\"]}\n",
    "                \"\"\"\n",
    "        \n",
    "        # Create personalized output\n",
    "        output = f\"Based on your data, I notice your highest carbon footprint comes from {highest_area}. Here are 4 personalized recommendations to reduce your carbon footprint:\\n\\n\"\n",
    "        \n",
    "        for i, tip in enumerate(selected_tips, 1):\n",
    "            # Add personalization based on user data\n",
    "            personalized_comment = \"\"\n",
    "            if highest_area == \"Transport\" and profile[\"current_activities\"][\"transport\"][\"mode\"] == \"car\":\n",
    "                personalized_comment = f\" This is especially relevant since you drive {profile['current_activities']['transport']['distance_km_per_day']} km daily.\"\n",
    "            elif highest_area == \"Home\" and tip[\"title\"].lower().find(\"energy\") >= 0:\n",
    "                personalized_comment = f\" Given your monthly electricity usage of {profile['current_activities']['home']['electricity_usage_kwh_per_month']} kWh, this could significantly reduce your footprint.\"\n",
    "            elif highest_area == \"Food\" and profile[\"current_activities\"][\"food\"][\"food_waste\"] in [\"high\", \"medium\"]:\n",
    "                personalized_comment = f\" Since your food waste is {profile['current_activities']['food']['food_waste']}, this tip could make a big difference.\"\n",
    "            \n",
    "            output += f\"{i}. **{tip['title']}**: {tip['description']}{personalized_comment}\\n\\n\"\n",
    "        \n",
    "        output += f\"By focusing on these {highest_area.lower()}-related changes, you could significantly reduce your carbon footprint of {profile['carbon_footprint_total']} kg and improve your eco-score above {profile['eco_score']}.\"\n",
    "        \n",
    "        examples.append({\n",
    "            \"instruction\": instruction,\n",
    "            \"input\": input_context,\n",
    "            \"output\": output\n",
    "        })\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Generate synthetic user profiles\n",
    "user_profiles = generate_user_profiles(num_profiles=2000)\n",
    "\n",
    "# Create recommendation examples\n",
    "examples = create_recommendation_examples(user_profiles, reference_data)\n",
    "\n",
    "# Split into train and validation sets\n",
    "random.shuffle(examples)\n",
    "train_examples = examples[:int(0.9 * len(examples))]\n",
    "val_examples = examples[int(0.9 * len(examples)):]\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_list(train_examples)\n",
    "val_dataset = Dataset.from_list(val_examples)\n",
    "\n",
    "# Save datasets to disk\n",
    "train_dataset.save_to_disk(\"carbon_footprint_train\")\n",
    "val_dataset.save_to_disk(\"carbon_footprint_val\")\n",
    "\n",
    "print(f\"Created {len(train_examples)} training examples and {len(val_examples)} validation examples\")\n",
    "print(\"Sample instruction:\", train_examples[0][\"instruction\"])\n",
    "print(\"Sample input:\", train_examples[0][\"input\"][:200] + \"...\")\n",
    "print(\"Sample output:\", train_examples[0][\"output\"][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://huggingface.co/meta-llama/Llama-2-7b-hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Fine-tuning Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_from_disk\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     AutoModelForCausalLM,\n\u001b[0;32m      6\u001b[0m     AutoTokenizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     logging\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32md:\\py_venv\\Lib\\site-packages\\torch\\__init__.py:274\u001b[0m\n\u001b[0;32m    270\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    272\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 274\u001b[0m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\py_venv\\Lib\\site-packages\\torch\\__init__.py:250\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    248\u001b[0m is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[1;32m--> 250\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mkernel32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibraryExW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0x00001100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     last_error \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mget_last_error()\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m126\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    "    PeftModel\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define model path - change this to your model path\n",
    "MODEL_PATH = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # or \"meta-llama/Llama-2-7b-hf\"\n",
    "OUTPUT_DIR = \"carbon_footprint_model\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = load_from_disk(\"carbon_footprint_train\")\n",
    "val_dataset = load_from_disk(\"carbon_footprint_val\")\n",
    "\n",
    "print(f\"Loaded {len(train_dataset)} training examples and {len(val_dataset)} validation examples\")\n",
    "\n",
    "# Configure quantization for efficiency\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Prepare model for training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Configure LoRA\n",
    "peft_config = LoraConfig(\n",
    "    r=16,  # rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    ")\n",
    "\n",
    "# Apply LoRA to model\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Print trainable parameters\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(f\"Trainable params: {trainable_params} || All params: {all_params} || Trainable%: {100 * trainable_params / all_params:.2f}%\")\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    warmup_steps=100,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"wandb\",  # Comment this out if you don't want to use Weights & Biases\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Format dataset for instruction fine-tuning\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    \n",
    "    prompts = []\n",
    "    for instruction, input_text, output in zip(instructions, inputs, outputs):\n",
    "        if input_text:\n",
    "            prompt = f\"<s>[INST] {instruction}\\n\\n{input_text} [/INST] {output} </s>\"\n",
    "        else:\n",
    "            prompt = f\"<s>[INST] {instruction} [/INST] {output} </s>\"\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return {\"text\": prompts}\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=None,  # We're using a custom formatting function\n",
    "    max_seq_length=2048,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model\n",
    "trainer.save_model(f\"{OUTPUT_DIR}/final\")\n",
    "\n",
    "# Merge LoRA weights with base model for easier deployment\n",
    "model = PeftModel.from_pretrained(\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATH, \n",
    "        torch_dtype=torch.float16, \n",
    "        device_map=\"auto\", \n",
    "        trust_remote_code=True\n",
    "    ),\n",
    "    f\"{OUTPUT_DIR}/final\",\n",
    ")\n",
    "\n",
    "# Merge adapter weights with base model\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "# Save merged model\n",
    "merged_model.save_pretrained(f\"{OUTPUT_DIR}/merged\", safe_serialization=True)\n",
    "tokenizer.save_pretrained(f\"{OUTPUT_DIR}/merged\")\n",
    "\n",
    "print(\"Training completed and model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model_path = \"carbon_footprint_model/merged\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Create a text generation pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "# Sample user data for testing\n",
    "test_instruction = \"Give me 4 suggestion tips on reduction of Carbon footprint based on my user data.\"\n",
    "test_input = \"\"\"\n",
    "USER BEHAVIOR DATA:\n",
    "- Eco-Score: 65.3\n",
    "- Carbon Footprint [kg] total: 12500.75\n",
    "  - Transport: 4850.25\n",
    "  - Home: 3200.50\n",
    "  - Food: 2800.00\n",
    "  - Shopping: 1650.00\n",
    "- Water Saved: 450.5\n",
    "- Energy Saved: 750.2\n",
    "- Waste Reduced: 220.1\n",
    "- User Plan: Drive less - Driving a car is a major source of greenhouse gasses. Cutting down on the miles you drive is one of the best things you can do for reducing carbon emissions.\n",
    "- Current User Activity:\n",
    "  - Mode of transport: car, distance: 35.5 km/day\n",
    "  - Home Energy source: grid electricity, Electricity Usage: 450.25 kWh/month, Heating Type: gas\n",
    "  - Food diet type: omnivore, Food Waste: high, Organic food consumption: occasional\n",
    "\"\"\"\n",
    "\n",
    "# Format the prompt according to the model's expected format\n",
    "prompt = f\"<s>[INST] {test_instruction}\\n\\n{test_input} [/INST]\"\n",
    "\n",
    "# Generate recommendations\n",
    "generated_text = pipe(prompt)[0][\"generated_text\"]\n",
    "\n",
    "# Extract just the model's response (after the instruction)\n",
    "response = generated_text.split(\"[/INST]\")[1].strip()\n",
    "\n",
    "print(\"Generated recommendations:\")\n",
    "print(response)\n",
    "\n",
    "# Create a simple evaluation function\n",
    "def evaluate_recommendations(response):\n",
    "    criteria = {\n",
    "        \"personalization\": \"Does the response reference specific user data?\",\n",
    "        \"relevance\": \"Are the recommendations relevant to the user's highest carbon footprint area?\",\n",
    "        \"actionability\": \"Are the recommendations specific and actionable?\",\n",
    "        \"completeness\": \"Does the response provide exactly 4 recommendations?\"\n",
    "    }\n",
    "    \n",
    "    print(\"\\nEvaluation criteria:\")\n",
    "    for criterion, description in criteria.items():\n",
    "        print(f\"- {criterion}: {description}\")\n",
    "    \n",
    "    print(\"\\nPlease manually evaluate the response based on these criteria.\")\n",
    "\n",
    "evaluate_recommendations(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Components\n",
    "1. Quantitative Metrics for Evaluation\n",
    "\n",
    "Let's create a robust evaluation script that will help you visualize and analyze \n",
    "\n",
    "your model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import evaluate\n",
    "import re\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_palette(\"deep\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model_path = \"carbon_footprint_model/merged\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load validation dataset\n",
    "val_dataset = load_from_disk(\"carbon_footprint_val\")\n",
    "print(f\"Loaded {len(val_dataset)} validation examples\")\n",
    "\n",
    "# Define evaluation metrics\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Helper function to extract numerical values from user data\n",
    "def extract_carbon_values(input_text):\n",
    "    # Extract total footprint\n",
    "    total_match = re.search(r'Carbon Footprint \\[kg\\] total: (\\d+\\.\\d+)', input_text)\n",
    "    total = float(total_match.group(1)) if total_match else 0\n",
    "    \n",
    "    # Extract breakdown\n",
    "    transport_match = re.search(r'Transport: (\\d+\\.\\d+)', input_text)\n",
    "    home_match = re.search(r'Home: (\\d+\\.\\d+)', input_text)\n",
    "    food_match = re.search(r'Food: (\\d+\\.\\d+)', input_text)\n",
    "    shopping_match = re.search(r'Shopping: (\\d+\\.\\d+)', input_text)\n",
    "    \n",
    "    transport = float(transport_match.group(1)) if transport_match else 0\n",
    "    home = float(home_match.group(1)) if home_match else 0\n",
    "    food = float(food_match.group(1)) if food_match else 0\n",
    "    shopping = float(shopping_match.group(1)) if shopping_match else 0\n",
    "    \n",
    "    return {\n",
    "        'total': total,\n",
    "        'transport': transport,\n",
    "        'home': home,\n",
    "        'food': food,\n",
    "        'shopping': shopping\n",
    "    }\n",
    "\n",
    "# Helper function for semantic metric evaluation\n",
    "def calculate_semantic_metrics(reference, prediction):\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = rouge_scorer.score(reference, prediction)\n",
    "    \n",
    "    # Calculate METEOR score\n",
    "    meteor_score = meteor.compute(predictions=[prediction], references=[reference])\n",
    "    \n",
    "    # Calculate BERTScore\n",
    "    bert_scores = bertscore.compute(\n",
    "        predictions=[prediction], \n",
    "        references=[reference], \n",
    "        lang=\"en\",\n",
    "        model_type=\"microsoft/deberta-xlarge-mnli\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'rouge1': rouge_scores['rouge1'].fmeasure,\n",
    "        'rouge2': rouge_scores['rouge2'].fmeasure,\n",
    "        'rougeL': rouge_scores['rougeL'].fmeasure,\n",
    "        'meteor': meteor_score['meteor'],\n",
    "        'bert_precision': bert_scores['precision'][0],\n",
    "        'bert_recall': bert_scores['recall'][0],\n",
    "        'bert_f1': bert_scores['f1'][0]\n",
    "    }\n",
    "\n",
    "# Function to check if recommendation matches highest footprint area\n",
    "def recommendation_matches_footprint(carbon_values, prediction):\n",
    "    # Determine highest footprint area\n",
    "    footprint_areas = {\n",
    "        'transport': carbon_values['transport'],\n",
    "        'home': carbon_values['home'],\n",
    "        'food': carbon_values['food'],\n",
    "        'shopping': carbon_values['shopping']\n",
    "    }\n",
    "    highest_area = max(footprint_areas, key=footprint_areas.get)\n",
    "    \n",
    "    # Check if the highest area is prominently mentioned in the recommendation\n",
    "    area_patterns = {\n",
    "        'transport': ['transport', 'car', 'driving', 'vehicle', 'commute', 'travel'],\n",
    "        'home': ['home', 'electricity', 'energy', 'heating', 'cooling', 'appliance'],\n",
    "        'food': ['food', 'diet', 'meat', 'vegetarian', 'organic', 'waste'],\n",
    "        'shopping': ['shop', 'purchase', 'buy', 'product', 'consumer']\n",
    "    }\n",
    "    \n",
    "    prediction_lower = prediction.lower()\n",
    "    area_mentions = sum(1 for term in area_patterns[highest_area] if term in prediction_lower)\n",
    "    other_area_mentions = sum(\n",
    "        1 for area, terms in area_patterns.items() \n",
    "        if area != highest_area \n",
    "        for term in terms if term in prediction_lower\n",
    "    )\n",
    "    \n",
    "    # Check if recommendations focus on the highest area\n",
    "    return {\n",
    "        'highest_area': highest_area,\n",
    "        'highest_area_mentions': area_mentions,\n",
    "        'other_areas_mentions': other_area_mentions,\n",
    "        'focused_on_highest': area_mentions > other_area_mentions\n",
    "    }\n",
    "\n",
    "# Function to count number of recommendations\n",
    "def count_recommendations(prediction):\n",
    "    # Look for numbered recommendations (1., 2., etc.)\n",
    "    numbered = len(re.findall(r'\\d+\\.\\s+\\*\\*', prediction))\n",
    "    \n",
    "    # If no numbered format, try other patterns\n",
    "    if numbered == 0:\n",
    "        numbered = len(re.findall(r'\\d+\\)\\s+', prediction))\n",
    "    \n",
    "    return numbered\n",
    "\n",
    "# Evaluate a batch of examples\n",
    "def evaluate_examples(examples, num_examples=50):\n",
    "    results = []\n",
    "    \n",
    "    for idx in tqdm(range(min(num_examples, len(examples)))):\n",
    "        example = examples[idx]\n",
    "        instruction = example['instruction']\n",
    "        input_text = example['input']\n",
    "        reference = example['output']\n",
    "        \n",
    "        # Format the prompt\n",
    "        prompt = f\"<s>[INST] {instruction}\\n\\n{input_text} [/INST]\"\n",
    "        \n",
    "        # Generate prediction\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_new_tokens=500,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "            )\n",
    "        \n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        prediction = generated_text.split(\"[/INST]\")[1].strip()\n",
    "        \n",
    "        # Extract carbon footprint values\n",
    "        carbon_values = extract_carbon_values(input_text)\n",
    "        \n",
    "        # Calculate semantic metrics\n",
    "        semantic_metrics = calculate_semantic_metrics(reference, prediction)\n",
    "        \n",
    "        # Check if recommendation matches highest footprint area\n",
    "        relevance_metrics = recommendation_matches_footprint(carbon_values, prediction)\n",
    "        \n",
    "        # Count recommendations\n",
    "        num_recommendations = count_recommendations(prediction)\n",
    "        \n",
    "        # Combine all metrics\n",
    "        result = {\n",
    "            'example_id': idx,\n",
    "            'carbon_footprint_total': carbon_values['total'],\n",
    "            'highest_area': relevance_metrics['highest_area'],\n",
    "            'num_recommendations': num_recommendations,\n",
    "            'focused_on_highest': relevance_metrics['focused_on_highest'],\n",
    "            'highest_area_mentions': relevance_metrics['highest_area_mentions'],\n",
    "            'other_areas_mentions': relevance_metrics['other_areas_mentions'],\n",
    "            **semantic_metrics\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run evaluation\n",
    "num_eval_examples = 50  # Adjust based on your computational resources\n",
    "results_df = evaluate_examples(val_dataset, num_eval_examples)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv(\"evaluation_results.csv\", index=False)\n",
    "print(\"Saved evaluation results to evaluation_results.csv\")\n",
    "\n",
    "# Create visualizations\n",
    "def create_evaluation_visualizations(results_df):\n",
    "    # Create a directory for plots\n",
    "    import os\n",
    "    os.makedirs(\"evaluation_plots\", exist_ok=True)\n",
    "    \n",
    "    # 1. Distribution of semantic metrics\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    semantic_metrics = ['rouge1', 'rouge2', 'rougeL', 'meteor', 'bert_f1']\n",
    "    \n",
    "    # Melt the dataframe for easier plotting\n",
    "    melted_df = pd.melt(results_df, value_vars=semantic_metrics, var_name='Metric', value_name='Score')\n",
    "    \n",
    "    # Create the violin plot\n",
    "    sns.violinplot(x='Metric', y='Score', data=melted_df)\n",
    "    plt.title('Distribution of Semantic Metrics', fontsize=16)\n",
    "    plt.xlabel('Metric', fontsize=14)\n",
    "    plt.ylabel('Score', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"evaluation_plots/semantic_metrics_distribution.png\", dpi=300)\n",
    "    \n",
    "    # 2. Recommendation focus by highest footprint area\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    area_focus = results_df.groupby('highest_area')['focused_on_highest'].mean() * 100\n",
    "    area_focus.plot(kind='bar', color='teal')\n",
    "    plt.title('Percentage of Recommendations Focused on Highest Footprint Area', fontsize=16)\n",
    "    plt.xlabel('Highest Footprint Area', fontsize=14)\n",
    "    plt.ylabel('Percentage Focused (%)', fontsize=14)\n",
    "    plt.axhline(y=50, color='r', linestyle='--', alpha=0.7)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"evaluation_plots/recommendation_focus_by_area.png\", dpi=300)\n",
    "    \n",
    "    # 3. Number of recommendations provided\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='num_recommendations', data=results_df, palette='viridis')\n",
    "    plt.title('Number of Recommendations Provided', fontsize=16)\n",
    "    plt.xlabel('Number of Recommendations', fontsize=14)\n",
    "    plt.ylabel('Count', fontsize=14)\n",
    "    plt.axvline(x=3.5, color='r', linestyle='--', alpha=0.7, label='Target (4)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"evaluation_plots/recommendation_count.png\", dpi=300)\n",
    "    \n",
    "    # 4. Correlation between metrics\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_columns = semantic_metrics + ['highest_area_mentions', 'other_areas_mentions', 'num_recommendations']\n",
    "    correlation = results_df[correlation_columns].corr()\n",
    "    mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "    sns.heatmap(correlation, mask=mask, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "    plt.title('Correlation Between Evaluation Metrics', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"evaluation_plots/metrics_correlation.png\", dpi=300)\n",
    "    \n",
    "    # 5. Performance by footprint area (BERT F1 score)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='highest_area', y='bert_f1', data=results_df, palette='Set2')\n",
    "    plt.title('Model Performance (BERT F1) by Highest Footprint Area', fontsize=16)\n",
    "    plt.xlabel('Highest Footprint Area', fontsize=14)\n",
    "    plt.ylabel('BERT F1 Score', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"evaluation_plots/performance_by_area.png\", dpi=300)\n",
    "    \n",
    "    # 6. Scatter plot of BERT F1 vs Recommendation focus\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(\n",
    "        results_df['highest_area_mentions'], \n",
    "        results_df['bert_f1'], \n",
    "        alpha=0.7, \n",
    "        c=results_df['focused_on_highest'].map({True: 'green', False: 'red'})\n",
    "    )\n",
    "    plt.title('Relationship Between Recommendation Focus and Quality', fontsize=16)\n",
    "    plt.xlabel('Number of Mentions of Highest Footprint Area', fontsize=14)\n",
    "    plt.ylabel('BERT F1 Score', fontsize=14)\n",
    "    plt.colorbar(plt.cm.ScalarMappable(cmap='RdYlGn'), label='Focused on Highest Area')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"evaluation_plots/focus_vs_quality.png\", dpi=300)\n",
    "    \n",
    "    print(\"Created evaluation visualizations in 'evaluation_plots' directory\")\n",
    "\n",
    "# Generate visualizations\n",
    "create_evaluation_visualizations(results_df)\n",
    "\n",
    "# Create a summary report\n",
    "def create_summary_report(results_df):\n",
    "    summary = {\n",
    "        \"num_examples_evaluated\": len(results_df),\n",
    "        \"semantic_metrics\": {\n",
    "            metric: {\n",
    "                \"mean\": results_df[metric].mean(),\n",
    "                \"median\": results_df[metric].median(),\n",
    "                \"std\": results_df[metric].std()\n",
    "            } for metric in ['rouge1', 'rouge2', 'rougeL', 'meteor', 'bert_f1']\n",
    "        },\n",
    "        \"focused_on_highest_area\": {\n",
    "            \"overall_percentage\": results_df['focused_on_highest'].mean() * 100,\n",
    "            \"by_area\": {\n",
    "                area: {\n",
    "                    \"percentage\": group['focused_on_highest'].mean() * 100,\n",
    "                    \"count\": len(group)\n",
    "                }\n",
    "                for area, group in results_df.groupby('highest_area')\n",
    "            }\n",
    "        },\n",
    "        \"recommendation_count\": {\n",
    "            \"mean\": results_df['num_recommendations'].mean(),\n",
    "            \"exactly_four_percentage\": (results_df['num_recommendations'] == 4).mean() * 100\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save summary as JSON\n",
    "    with open(\"evaluation_summary.json\", \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n===== Evaluation Summary =====\")\n",
    "    print(f\"Number of examples evaluated: {summary['num_examples_evaluated']}\")\n",
    "    print(\"\\nSemantic Metrics:\")\n",
    "    for metric, values in summary['semantic_metrics'].items():\n",
    "        print(f\"  {metric}: mean={values['mean']:.3f}, median={values['median']:.3f}\")\n",
    "    \n",
    "    print(\"\\nRecommendation Relevance:\")\n",
    "    print(f\"  Overall focused on highest footprint area: {summary['focused_on_highest_area']['overall_percentage']:.1f}%\")\n",
    "    for area, stats in summary['focused_on_highest_area']['by_area'].items():\n",
    "        print(f\"  {area.capitalize()}: {stats['percentage']:.1f}% focused (from {stats['count']} examples)\")\n",
    "    \n",
    "    print(\"\\nRecommendation Count:\")\n",
    "    print(f\"  Average number of recommendations: {summary['recommendation_count']['mean']:.2f}\")\n",
    "    print(f\"  Percentage with exactly 4 recommendations: {summary['recommendation_count']['exactly_four_percentage']:.1f}%\")\n",
    "    \n",
    "    print(\"\\nSaved detailed summary to evaluation_summary.json\")\n",
    "\n",
    "# Generate summary report\n",
    "create_summary_report(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_path = \"carbon_footprint_model/merged\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load validation dataset\n",
    "val_dataset = load_from_disk(\"carbon_footprint_val\")\n",
    "\n",
    "# Create directory for human evaluation results\n",
    "os.makedirs(\"human_evaluation\", exist_ok=True)\n",
    "\n",
    "# Generate a prediction for a given example\n",
    "def generate_prediction(example):\n",
    "    instruction = example['instruction']\n",
    "    input_text = example['input']\n",
    "    reference = example['output']\n",
    "    \n",
    "    # Format the prompt\n",
    "    prompt = f\"<s>[INST] {instruction}\\n\\n{input_text} [/INST]\"\n",
    "    \n",
    "    # Generate prediction\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=500,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    prediction = generated_text.split(\"[/INST]\")[1].strip()\n",
    "    \n",
    "    return prediction, reference, input_text\n",
    "\n",
    "# Human evaluation interface\n",
    "def evaluate_sample(example_id=None):\n",
    "    if example_id is None or example_id >= len(val_dataset):\n",
    "        example_id = random.randint(0, len(val_dataset) - 1)\n",
    "    \n",
    "    example = val_dataset[example_id]\n",
    "    prediction, reference, input_text = generate_prediction(example)\n",
    "    \n",
    "    return example_id, input_text, prediction, reference\n",
    "\n",
    "def save_evaluation(example_id, relevance, specificity, personalization, actionability, overall, comments):\n",
    "    evaluation = {\n",
    "        \"example_id\": example_id,\n",
    "        \"scores\": {\n",
    "            \"relevance\": relevance,\n",
    "            \"specificity\": specificity,\n",
    "            \"personalization\": personalization,\n",
    "            \"actionability\": actionability,\n",
    "            \"overall\": overall\n",
    "        },\n",
    "        \"comments\": comments\n",
    "    }\n",
    "    \n",
    "    # Save individual evaluation\n",
    "    filename = f\"human_evaluation/example_{example_id}.json\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(evaluation, f, indent=2)\n",
    "    \n",
    "    # Update summary file\n",
    "    summary_file = \"human_evaluation/summary.csv\"\n",
    "    evaluation_row = {\n",
    "        \"example_id\": example_id,\n",
    "        \"relevance\": relevance,\n",
    "        \"specificity\": specificity,\n",
    "        \"personalization\": personalization,\n",
    "        \"actionability\": actionability,\n",
    "        \"overall\": overall,\n",
    "        \"comments\": comments\n",
    "    }\n",
    "    \n",
    "    if os.path.exists(summary_file):\n",
    "        summary_df = pd.read_csv(summary_file)\n",
    "        # Check if this example is already evaluated\n",
    "        if example_id in summary_df[\"example_id\"].values:\n",
    "            summary_df = summary_df[summary_df[\"example_id\"] != example_id]\n",
    "        summary_df = pd.concat([summary_df, pd.DataFrame([evaluation_row])])\n",
    "    else:\n",
    "        summary_df = pd.DataFrame([evaluation_row])\n",
    "    \n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    \n",
    "    return f\"Evaluation for example {example_id} saved successfully!\"\n",
    "\n",
    "def show_summary():\n",
    "    summary_file = \"human_evaluation/summary.csv\"\n",
    "    if not os.path.exists(summary_file):\n",
    "        return \"No evaluations have been completed yet.\"\n",
    "    \n",
    "    df = pd.read_csv(summary_file)\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        return \"No evaluations have been completed yet.\"\n",
    "    \n",
    "    avg_scores = df[[\"relevance\", \"specificity\", \"personalization\", \"actionability\", \"overall\"]].mean()\n",
    "    \n",
    "    summary = \"## Human Evaluation Summary\\n\\n\"\n",
    "    summary += f\"Number of examples evaluated: {len(df)}\\n\\n\"\n",
    "    summary += \"### Average Scores (1-5 scale):\\n\"\n",
    "    summary += f\"- Relevance: {avg_scores['relevance']:.2f}\\n\"\n",
    "    summary += f\"- Specificity: {avg_scores['specificity']:.2f}\\n\"\n",
    "    summary += f\"- Personalization: {avg_scores['personalization']:.2f}\\n\"\n",
    "    summary += f\"- Actionability: {avg_scores['actionability']:.2f}\\n\"\n",
    "    summary += f\"- Overall Quality: {avg_scores['overall']:.2f}\\n\\n\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(title=\"Human Evaluation of Carbon Footprint Recommendations\") as demo:\n",
    "    gr.Markdown(\"# Human Evaluation of Carbon Footprint Recommendations\")\n",
    "    gr.Markdown(\"\"\"\n",
    "    This tool allows you to evaluate the quality of model-generated recommendations.\n",
    "    \n",
    "    Rate each recommendation on the following criteria (1-5 scale):\n",
    "    - **Relevance**: How well the recommendations address the user's highest carbon footprint area\n",
    "    - **Specificity**: How detailed and specific the recommendations are\n",
    "    - **Personalization**: How well the recommendations are tailored to the user's data\n",
    "    - **Actionability**: How practical and implementable the recommendations are\n",
    "    - **Overall Quality**: Your overall impression of the recommendations\n",
    "    \"\"\")\n",
    "    \n",
    "    example_id_state = gr.State(0)\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            example_id_input = gr.Number(label=\"Example ID (leave empty for random)\", precision=0)\n",
    "            load_btn = gr.Button(\"Load Example\")\n",
    "            random_btn = gr.Button(\"Load Random Example\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            summary_btn = gr.Button(\"Show Evaluation Summary\")\n",
    "            summary_output = gr.Markdown(label=\"Summary\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### User Data\")\n",
    "            user_data = gr.TextArea(label=\"User Input Data\", interactive=False, lines=20)\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    gr.Markdown(\"### Model Recommendation\")\n",
    "                    model_output = gr.TextArea(label=\"Model Generated Recommendation\", interactive=False, lines=15)\n",
    "                with gr.Column():\n",
    "                    gr.Markdown(\"### Reference Recommendation\")\n",
    "                    reference_output = gr.TextArea(label=\"Reference Recommendation\", interactive=False, lines=15)\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            relevance = gr.Slider(1, 5, 3, step=1, label=\"Relevance\")\n",
    "            specificity = gr.Slider(1, 5, 3, step=1, label=\"Specificity\")\n",
    "            personalization = gr.Slider(1, 5, 3, step=1, label=\"Personalization\")\n",
    "            actionability = gr.Slider(1, 5, 3, step=1, label=\"Actionability\")\n",
    "            overall = gr.Slider(1, 5, 3, step=1, label=\"Overall Quality\")\n",
    "            comments = gr.TextArea(label=\"Comments/Observations\", lines=3)\n",
    "            submit_btn = gr.Button(\"Submit Evaluation\")\n",
    "            result_output = gr.Markdown()\n",
    "    \n",
    "    # Define update function\n",
    "    def update_interface(example_id=None):\n",
    "        example_id, input_text, prediction, reference = evaluate_sample(example_id)\n",
    "        return example_id, input_text, prediction, reference\n",
    "    \n",
    "    # Set up button actions\n",
    "    load_btn.click(\n",
    "        update_interface, \n",
    "        inputs=[example_id_input], \n",
    "        outputs=[example_id_state, user_data, model_output, reference_output]\n",
    "    )\n",
    "    \n",
    "    random_btn.click(\n",
    "        update_interface, \n",
    "        inputs=[], \n",
    "        outputs=[example_id_state, user_data, model_output, reference_output]\n",
    "    )\n",
    "    \n",
    "    submit_btn.click(\n",
    "        save_evaluation,\n",
    "        inputs=[example_id_state, relevance, specificity, personalization, actionability, overall, comments],\n",
    "        outputs=[result_output]\n",
    "    )\n",
    "    \n",
    "    summary_btn.click(show_summary, inputs=[], outputs=[summary_output])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Training History Visualization\n",
    "To visualize how your model improved during training, you can create a script to analyze the training logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "def extract_training_logs(log_file):\n",
    "    \"\"\"Extract training metrics from log file\"\"\"\n",
    "    logs = []\n",
    "    \n",
    "    with open(log_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'loss' in line:\n",
    "                # Try to parse JSON\n",
    "                try:\n",
    "                    log_entry = json.loads(line)\n",
    "                    logs.append(log_entry)\n",
    "                except:\n",
    "                    # If not JSON, try regex\n",
    "                    match = re.search(r'loss[=:]?\\s*([0-9.]+)', line)\n",
    "                    if match:\n",
    "                        loss = float(match.group(1))\n",
    "                        step_match = re.search(r'step[=:]?\\s*([0-9]+)', line)\n",
    "                        step = int(step_match.group(1)) if step_match else len(logs) + 1\n",
    "                        logs.append({\"loss\": loss, \"step\": step})\n",
    "    \n",
    "    return pd.DataFrame(logs)\n",
    "\n",
    "def plot_training_progress(log_df, output_dir=\"training_plots\"):\n",
    "    \"\"\"Create visualizations of training progress\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Loss curve\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(x='step', y='loss', data=log_df)\n",
    "    plt.title('Training Loss Over Time', fontsize=16)\n",
    "    plt.xlabel('Training Step', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/training_loss.png\", dpi=300)\n",
    "    \n",
    "    # 2. Rolling average loss (to smooth the curve)\n",
    "    if len(log_df) > 10:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        log_df['rolling_loss'] = log_df['loss'].rolling(window=10).mean()\n",
    "        sns.lineplot(x='step', y='rolling_loss', data=log_df)\n",
    "        plt.title('10-Step Rolling Average Training Loss', fontsize=16)\n",
    "        plt.xlabel('Training Step', fontsize=14)\n",
    "        plt.ylabel('Loss (Rolling Average)', fontsize=14)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/rolling_avg_loss.png\", dpi=300)\n",
    "    \n",
    "    # 3. Loss distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(log_df['loss'], kde=True)\n",
    "    plt.title('Distribution of Training Loss Values', fontsize=16)\n",
    "    plt.xlabel('Loss', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/loss_distribution.png\", dpi=300)\n",
    "    \n",
    "    # 4. Loss improvement visualization\n",
    "    if len(log_df) > 20:\n",
    "        # Split data into 5 equal parts to show progression\n",
    "        splits = np.array_split(log_df, 5)\n",
    "        medians = [split['loss'].median() for split in splits]\n",
    "        stages = [f'Stage {i+1}' for i in range(5)]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=stages, y=medians)\n",
    "        plt.title('Median Loss Across Training Stages', fontsize=16)\n",
    "        plt.xlabel('Training Stage', fontsize=14)\n",
    "        plt.ylabel('Median Loss', fontsize=14)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/loss_stages.png\", dpi=300)\n",
    "    \n",
    "    # 5. If we have learning rate data\n",
    "    if 'learning_rate' in log_df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.lineplot(x='step', y='learning_rate', data=log_df)\n",
    "        plt.title('Learning Rate Schedule', fontsize=16)\n",
    "        plt.xlabel('Training Step', fontsize=14)\n",
    "        plt.ylabel('Learning Rate', fontsize=14)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/learning_rate.png\", dpi=300)\n",
    "    \n",
    "    print(f\"Training visualization plots saved to {output_dir}\")\n",
    "\n",
    "# Try to find training logs\n",
    "def find_training_logs(output_dir=\"carbon_footprint_model\"):\n",
    "    \"\"\"Find training log files in the output directory\"\"\"\n",
    "    log_patterns = [\n",
    "        # Common log patterns\n",
    "        f\"{output_dir}/*/trainer_state.json\",\n",
    "        f\"{output_dir}/*log*\",\n",
    "        f\"{output_dir}/*.log\",\n",
    "        \"training.log\"\n",
    "    ]\n",
    "    \n",
    "    all_logs = []\n",
    "    for pattern in log_patterns:\n",
    "        all_logs.extend(glob(pattern))\n",
    "    \n",
    "    return all_logs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Find log files\n",
    "    log_files = find_training_logs()\n",
    "    \n",
    "    if not log_files:\n",
    "        print(\"No log files found. Please provide the path to your training logs.\")\n",
    "        log_path = input(\"Training log file path: \")\n",
    "        if os.path.exists(log_path):\n",
    "            log_files = [log_path]\n",
    "        else:\n",
    "            print(f\"File not found: {log_path}\")\n",
    "            exit(1)\n",
    "    \n",
    "    # Process each log file\n",
    "    for log_file in log_files:\n",
    "        print(f\"Processing log file: {log_file}\")\n",
    "        try:\n",
    "            log_df = extract_training_logs(log_file)\n",
    "            \n",
    "            if len(log_df) > 0:\n",
    "                print(f\"Found {len(log_df)} log entries\")\n",
    "                output_dir = f\"training_plots_{os.path.basename(log_file).split('.')[0]}\"\n",
    "                plot_training_progress(log_df, output_dir)\n",
    "            else:\n",
    "                print(\"No valid log entries found in this file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {log_file}: {e}\")\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
